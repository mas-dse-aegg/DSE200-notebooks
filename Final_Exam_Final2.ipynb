{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DSE 200 Final Exam\n",
    "There are **seven** problems listed below in approximatly increacing difficulty and length.\n",
    "Most problems involve just a couple lines of code denoted by comments within the code.\n",
    "If a problem seems to require a ton of code you are likely over thinking it and should try to find a simpler solution.\n",
    "\n",
    "Here are the topics of each problem:\n",
    "1. Exception Handling\n",
    "2. Unix Piping\n",
    "3. Directory Walking\n",
    "4. Linear Regression\n",
    "5. Object Oriented Model Selection\n",
    "6. Scraping\n",
    "7. Matplotlib\n",
    "\n",
    "This test is open internet; however, communication with your peers/others is strictly prohibited.  \n",
    "\n",
    "Good Luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Exception Handling\n",
    "\n",
    "Write a function to add two numbers, if either of the arguements is not an int or float, throw a new ArguementsMustBeNumbers exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ArguementsMustBeNumbers(Exception):\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=1\n",
    "type(x) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_two(x,y):\n",
    "    if False:#Check types of x and y\n",
    "        raise ArguementsMustBeNumbers()\n",
    "    return x+y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this code is correctly implemented, the following code should print True 4 times (no exceptions should be uncaught)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print add_two(1,1)==2\n",
    "try:\n",
    "    add_two(\"t\",1)\n",
    "    print False\n",
    "except ArguementsMustBeNumbers:\n",
    "    print True\n",
    "try:\n",
    "    add_two(2,\"f\")\n",
    "    print False\n",
    "except ArguementsMustBeNumbers:\n",
    "    print True\n",
    "try:\n",
    "    add_two(\"t\",\"f\")\n",
    "    print False\n",
    "except ArguementsMustBeNumbers:\n",
    "    print True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Unix Piping \n",
    "\n",
    "Below we generate a file called ps_out which contains a details about all processes on our machine.  In particular it is a csv file containing the PID, Username which owns the process, and the percent of the CPU time occupied by it.\n",
    "\n",
    "We'll ask you to process this file using unix tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do not modify this section\n",
    "!ps -Ao \"pid,user,%cpu\" | sed \"s/^ *//\" | sed \"s/  */,/g\" > ps_out\n",
    "!head ps_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, using **only unix tools**, count the number of processes each user is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ps_out #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, using **only unix tools**, find the pid which is using the largest cpu %.\n",
    "\n",
    "Your output should only be a single number (the process id consuming the largest cpu amount), i.e. `30048`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ps_out #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Directory Walking\n",
    "\n",
    "Below we have written a program which uses os.walk, unix tools, and python to find the 3 longest files by line count within each directory under the /etc/ directory.\n",
    "\n",
    "However, it is currently has several problems which you are tasked with fixing.\n",
    "\n",
    "Here are the current problems which must be fixed:\n",
    "\n",
    "1. the output is not sorted by line count\n",
    "2. the \"total\" line listing the total lines across the directory is not a file and should be removed\n",
    "3. more than three files are being printed\n",
    "4. directories that contain no files are being printed\n",
    "\n",
    "These issues should be resolved by using a combintation of python and or unix commands.  Please ensure the output format is not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import chain,groupby\n",
    "for d,ds,fs in os.walk(\"/tmp/\"):\n",
    "    #TODO: 1) Make output sorted by line count\n",
    "    #      2) Remove the Total line\n",
    "    #      3) Limit to 3 files per directory\n",
    "    #      4) Ignore directories containing no files\n",
    "    lines = !wc -l $d/* 2> /dev/null | sed \"s/^ *//\"\n",
    "    \n",
    "    files = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            fields = line.split(\" \")\n",
    "            files.append((int(fields[0]),fields[1]))\n",
    "        except ValueError:\n",
    "            print \"Bad line: \" + line\n",
    "                        \n",
    "    print \"Longest files in \" + d + \":\"\n",
    "    for lc, f in files:\n",
    "        print \"\\t%s\\t%d\" %(f,lc)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Linear Regression\n",
    "\n",
    "In the file linear.csv there is a set of 100 x,y pairs of numbers in csv format.\n",
    "\n",
    "About 10% of the lines have a missing y value.\n",
    "\n",
    "Your goal is to do the following:\n",
    "\n",
    "1. Preprocess the data to remove any points with a missing y value\n",
    "2. Fit a linear regression model using sklearn's LinearRegression package\n",
    "3. Plot a scatter plot of the populated x,y pairs as blue points and the best fit linear regression line in red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv(\"./linear.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocess the data to remove any points with a missing y value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = #Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a linear regression model using sklearn's LinearRegression package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = #Todo\n",
    "\n",
    "#Print formula so we can see the best fit line\n",
    "m = mdl.coef_[0]\n",
    "b = mdl.intercept_\n",
    "print \"formula: y = %f x + %f\" % (m,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a scatter plot of the populated x,y pairs as blue points and the best fit linear regression line in red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Object Oriented Model Selection\n",
    "\n",
    "Throughout the quarter, several problems have involved choosing the best model from a set of candidate models to get the best accuracy.\n",
    "\n",
    "Besides using it for selecting model hyperparmeters (as in grid search) or features, you can also use it to select the modeling method (regression, nearest neighbor, etc.).  \n",
    "\n",
    "We define three steps on the way to finding the best model.\n",
    "\n",
    "1. Define a base model class.\n",
    "1. Define four models by inheriting from a base model class.\n",
    "2. Use train/test errors to choose the best of the four model\n",
    "\n",
    "#### The base class\n",
    "We defined the base class, from which all of the other classes are derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do not modify this code\n",
    "class BaseModel:\n",
    "    def __init__(self, train_x, train_y):\n",
    "        \"\"\"Abstract constructor, subclasses should train a model of their type here and store\n",
    "           it in a way that predict can be used to compute predictions\"\"\"\n",
    "        raise Exception(\"This is an abstract class\")\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"Abstract method to compute a single prediction given a single example x\"\"\"\n",
    "        raise Exception(\"This is an abstract class\")\n",
    "        \n",
    "    def score(self, xs, ys):\n",
    "        \"\"\"Returns the accuracy of this model using xs as a list of inputs and ys as a list of correct values.\"\"\"\n",
    "        return sum([(self.model.predict(x)-y)**2 for x,y in zip(xs,ys)])/len(xs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have implemented the BaseModel, implement a class for LinearModel, QuadraticModel, CubicModel, and QuarticModel. Use numpy's [polyfit](http://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html) function to find the coefficients ($a_i$) using the training data given as parameters `train_x, train_y` to the constructor.\n",
    "\n",
    "The input to each model is the variable $x$ and the output is the variable $y$.  $a_i$ refers to the coefficients found by polyfit.\n",
    "\n",
    "* **LinearModel** $y=a_1x+a_0$\n",
    "* **QuadraticModel** $y=a_2x^2+a_1x+a_0$\n",
    "* **CubicModel** $y=a_3x^3+a_2x^2+a_1x+a_0$\n",
    "* **QuarticModel** $y=a_4x^4+a_3x^3+a_2x^2+a_1x+a_0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import polyfit\n",
    "\n",
    "#This model has been solved as below, and can be used as reference to write classes for models ahead.\n",
    "\n",
    "class LinearModel(BaseModel):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        #calculate coefficients\n",
    "        self.coef = polyfit(train_x, train_y,1)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        #use coeficients/formula to compute solution\n",
    "        y = self.coef[0] * x + self.coef[1]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QuadraticModel(BaseModel):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        #calculate coefficients\n",
    "        \n",
    "    def predict(self, x):\n",
    "        y = #use coeficients/formula to compute solution\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CubicModel(BaseModel):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        #calculate coefficients\n",
    "        \n",
    "    def predict(self, x):\n",
    "        y = #use coeficients/formula to compute solution\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QuarticModel(BaseModel):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        #calculate coefficients\n",
    "        \n",
    "    def predict(self, x):\n",
    "        y = #use coeficients/formula to compute solution\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we evaluate each of these models on our data.  Fill in the parts of the function marked \"TODO\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load Data, do not modify\n",
    "train = pd.read_csv(\"train_data.csv\")\n",
    "valid = pd.read_csv(\"validation_data.csv\")\n",
    "train_x = train[\"x\"].tolist()\n",
    "train_y = train[\"y\"].tolist()\n",
    "valid_x = valid[\"x\"].tolist()\n",
    "valid_y = valid[\"y\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Models = [LinearModel, QuadraticModel, CubicModel, QuarticModel]\n",
    "\n",
    "train_error = []\n",
    "valid_error = []\n",
    "for Model in Models:\n",
    "    mdl = #Todo: Learn model using technique\n",
    "    train_error.append(mdl.score(train_x,train_y))\n",
    "    valid_error.append(mdl.score(valid_x,valid_y))\n",
    "    \n",
    "#Todo: Find technique with minimum validation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally plot the training and validation error on the same plot.  Have a legend denoting which line is validation/training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Todo: Plot data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Scraping\n",
    "\n",
    "Started as a travel journal, Lonely Planet has gone on to become the world’s most successful travel publisher, and they maintain an award winning website giving all the necessary details a traveller could ask for. \n",
    "In this question we will try to use their website lonelyplanet.com to find the top sightseeing places in San diego and how far they are from our current location\n",
    "\n",
    "In order to do this, we will scrape the website to find the top sightseeing places and develop a table containing the name of the place and its corresponding latitude, longitude values. We will then define a function to calculate distance between two points given their latitude and longitude.\n",
    "\n",
    "You can take your current location as UCSD Rady School of Management, with Latitude 32.88661 and longitude -117.24128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "import lxml.html as lh\n",
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download the index of san diego sights for us to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "website = \"http://www.lonelyplanet.com\"\n",
    "country = \"usa\"\n",
    "city = \"san-diego\"\n",
    "scrape_topic = \"sights\"\n",
    "base_url = website+\"/\"+country+\"/\"+city+\"/\"+scrape_topic+\"/\"\n",
    "r  = requests.get(base_url)\n",
    "doc = lh.fromstring(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have retrieved the entire data from the website, The urls can be printed as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_elements=doc.xpath('//a')\n",
    "for a in a_elements:\n",
    "    print a.xpath('@href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next step is to extract the URLs corresponding to specific sights. \n",
    "\n",
    "In order to do so, we need to define a regular expression for the links in which we are interested. \n",
    "\n",
    "Browsing the HTML of the site we find URLs of the following type\n",
    "\n",
    "    1. /usa/san-diego/sights/\n",
    "    2. /usa/san-diego/sights/nature-wildlife/san-diego-zoo\n",
    "    3. /usa/san-diego/sights/architecture/hotel-del-coronado\n",
    "    4. /usa/san-diego/sights/?page2=id\n",
    "    5. /usa/san-diego/sights/?page1=id+data=x \n",
    "\n",
    "URLs like 2,3 correspond to pages of sights that we are interested in. On the other hand, URLs like 1,4,5 correspond to other information which is not of interest.\n",
    " \n",
    "Write a regex pattern which parses all links starting with /usa/san-diego/sights/ followed by more characters. Make sure that the pattern does not allow links with question marks such as 4,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = #TODO: Write regex to match desired URLS here\n",
    "url_list=[] #use the above pattern to create a list of matching urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the information about each sight, we provide the `makeRecord` function that takes a beutiful soup object and returns a Dictionary containing the location name, latitude, and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The following is a bottomline working code to proceed ahead if you are stuck. Points will be awarded form\n",
    "def makeRecord(doc):\n",
    "    record = {}\n",
    "    div_elements=doc.xpath('//div')\n",
    "    for div in div_elements:\n",
    "        if len(div.xpath('@data-latitude'))>0:\n",
    "            record[\"latitude\"] =div.xpath('@data-latitude')[0]\n",
    "        if len(div.xpath('@data-longitude'))>0:\n",
    "            record[\"longitude\"] =div.xpath('@data-longitude')[0]\n",
    "        record[\"title\"] = #write code to add title for the sight\n",
    "    return record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now loop through the sights pages you found and make records for each.  Fill in the template with the requested actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "website = \"http://www.lonelyplanet.com\"\n",
    "sights_list = []\n",
    "\n",
    "for url in url_list:\n",
    "    new_url = website+url\n",
    "    r    = #Use requests to get web page data\n",
    "    doc = lh.fromstring(r.content)\n",
    "    rec  = makeRecord(doc)\n",
    "    sights_list.append(rec)\n",
    "    \n",
    "sights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a table of sightseeiing places imediately around us along with their latitudes and longitudes, use the below function to find distance of each of the sightseeing place from your current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "import math\n",
    "def getDistanceFromLatLonInKm(lat1,lon1,lat2,lon2) :\n",
    "    R = 6371 # Radius of the earth in km\n",
    "    dLat = deg2rad(lat2-lat1) # deg2rad below\n",
    "    dLon = deg2rad(lon2-lon1) \n",
    "    a = math.sin(dLat/2)*math.sin(dLat/2)+math.cos(deg2rad(lat1))*math.cos(deg2rad(lat2))*math.sin(dLon/2)*math.sin(dLon/2)\n",
    "\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = R * c #Distance in km\n",
    "    return d\n",
    "\n",
    "\n",
    "def deg2rad(deg) :\n",
    "  return deg * (3.1416/180)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add a field to each record in `sights_list` called `distance` which reports the distance from the Rady School to it.  Then print the sights from closest to furthest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myLat = 32.88661\n",
    "myLng = -117.24128\n",
    "\n",
    "for i in range(len(sights_list)):\n",
    "    #Todo: add distance to record i in sights list\n",
    "    \n",
    "#Todo: sort sights_list\n",
    "\n",
    "for record in sights_list:\n",
    "    print record\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatplotLib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will plot a list of datasets in the form of histograms in the same plot. For this we will use the function plotHistograms given below, which takes a dataset, and bin count and outputs a histogram plot containing multiple horizonta bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAEmxJREFUeJzt3X+sZGV9x/H3BwksSmr8uUv4pfW3Jg1qssXQyLVGBdu4\n",
       "2BCVNPFXQ4iWaGLToELC1vQP9Q9SFY3FotFEg9ZGBJR2MXIlNBEJuAqyi2srCCt7ayIYkcWu8O0f\n",
       "M9Dxemfvj3PuzJ37vF/JZOecefY8z9nZ+cxznjnnPKkqJEltOWLaDZAkTZ7hL0kNMvwlqUGGvyQ1\n",
       "yPCXpAYZ/pLUoM7hn+SEJN9O8qMktyV5zxJlTk/yQJJbh4+LutYrSVq7I3vYxu+A91XV7iTHArck\n",
       "2VVVexeVu6Gq3tBDfZKkjjr3/KvqQFXtHj5/ENgDHL9E0XStS5LUj17H/JM8CzgFuGmJl1+RZHeS\n",
       "byR5cZ/1SpJWp49hHwCGQz5fBd47PAIYdQtwUlU9lORM4Erg+X3VLUlanfRxb58kRwLXANdW1cdW\n",
       "UP6nwMur6pdLvObNhiRplapqVUPrffX8PwvcMS74k2ytqoXh8+0MvnT+IPgfs9qdmBVJdlbVzmm3\n",
       "Y724f7PN/Ztda+k0dw7/JKcBfw3cluT7QAEfBE4GqqouA85O8i7gEHAQeHPXeiVJa9c5/KvqP4En\n",
       "LFPmk8Anu9YlSeqHV/hO1vy0G7DO5qfdgHU2P+0GrLP5aTdgnc1PuwEbSS8/+PYpSW3WMX9JWg9r\n",
       "yU17/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDTL8pUWSYw4kqZU/jjkw7TZLq+WpntIig0vlV/O5yKa9\n",
       "JYlmg6d6SpJWxPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWqQ4S9JDeoc/klOSPLtJD9KcluS94wp9/Ek\n",
       "+5LsTnJK13olSWvXxxy+vwPeV1W7kxwL3JJkV1XtfaxAkjOB51TV85L8KfBp4NQe6pYkrUHnnn9V\n",
       "Haiq3cPnDwJ7gOMXFdsBfGFY5ibgyUm2dq1bkrQ2vY75J3kWcApw06KXjgfuGVnezx9+QUiSJqSP\n",
       "YR8AhkM+XwXeOzwC6LKtnSOL81U132V7krSZJJkD5jpto48buyU5ErgGuLaqPrbE658Grq+qLw+X\n",
       "9wKnV9XCEmW9sZumyhu7adZM88ZunwXuWCr4h64C3gqQ5FTggaWCX5I0GZ17/klOA24AbmPQXSrg\n",
       "g8DJQFXVZcNylwJnAL8B3lFVt47Znj1/TZU9f82ateSm9/OXFjH8NWu8n78kaUUMf0lqkOEvSQ0y\n",
       "/CWpQYa/JDWotyt8pUlLjjkAD6/DPaKOBlZz4sTRwzOE+rZloergtv63K3mqp2bY6k/JnDWeQqqV\n",
       "8VRPSdKKGP6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBvUS/kkuT7KQ5IdjXj89\n",
       "yQNJbh0+LuqjXknS2vR1b5/PAZ8AvnCYMjdU1Rt6qk+S1EEvPf+quhG4f5li3qNEkjaISY75vyLJ\n",
       "7iTfSPLiCdYrSVpkUrd0vgU4qaoeSnImcCXw/HGFk+wcWZyvqvn1bZ4kzY4kc8Bcp230dUvnJCcD\n",
       "V1fVn6yg7E+Bl1fVL5d4zVs6a0W8pbM0MO1bOocx4/pJto48387gS+cPgl+SNBm9DPsk+RKDQ5Cn\n",
       "JfkZcDFwFFBVdRlwdpJ3AYeAg8Cb+6hXkrQ2zuSlmeWwjzQw7WEfSdKMMPwlqUGGvyQ1aFLn+Uvr\n",
       "YMujkE3cgdny6LRboM3L8NcMe/iITf6D7yb+YtO0+Z9Lkhpk+EtSgwx/SWqQ4S9JDTL8JalBhr8k\n",
       "Ncjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqUC/hn+TyJAtJfniYMh9Psi/J7iSn9FGvJGlt+ur5fw54\n",
       "3bgXk5wJPKeqngecB3y6p3olSWvQS/hX1Y3A/YcpsgP4wrDsTcCTRyd1lyRN1qTG/I8H7hlZ3j9c\n",
       "J0magg15P/8kO0cW56tqfkpNkaQNJ8kcMNdlG5MK//3AiSPLJwzXLamqdq53gyRpVg07xPOPLSe5\n",
       "eLXb6HPYJ8PHUq4C3gqQ5FTggapa6LFuSdIq9NLzT/IlBocgT0vyM+Bi4Cigquqyqvpmktcn+Qnw\n",
       "G+AdfdQrSVqbVG2sOVCTVFWNO4KQHpekNvkcvvhZ0EqsJTe9wleSGrQhz/bR+kqOOQAPb4LrLI5m\n",
       "/M9Mm8HRw6ObWbdloergtmm3Qr/PYZ8Gbf7hEm0sDl+tN4d9JEkrYvhLUoMMf0lqkOEvSQ0y/CWp\n",
       "QYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kN6iX8k5yRZG+SHye5YInXT0/yQJJbh4+L\n",
       "+qhXkrQ2nW/pnOQI4FLg1cDPgZuTfL2q9i4qekNVvaFrfZKk7vro+W8H9lXV3VV1CLgC2LFEOW/p\n",
       "KkkbRB/hfzxwz8jyvcN1i70iye4k30jy4h7qlSSt0aRm8roFOKmqHkpyJnAl8PwJ1S1JWqSP8N8P\n",
       "nDSyfMJw3eOq6sGR59cm+VSSp1bVL5faYJKdI4vzVTXfQzslaVNIMgfMddpG12kckzwBuJPBD773\n",
       "Ad8DzqmqPSNltlbVwvD5duArVfWsMdtzGsd15jSOmiyncVxva8nNzj3/qnokyfnALga/IVxeVXuS\n",
       "nDd4uS4Dzk7yLuAQcBB4c9d6JUlr5wTuDbLnr8my57/eptLzV3fJMQfg4a2Tq/FoPPNWk3P0sMMx\n",
       "KVsWqg5um1x9s8me/wZgT1zqU3tHGmvJTe/tI0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtS\n",
       "gwx/SWqQ4S9JDTL8JalBhr8kNcjwl6QGGf6S1CDDX5Ia1Ev4Jzkjyd4kP05ywZgyH0+yL8nuJKf0\n",
       "Ua8kaW06h3+SI4BLgdcBLwHOSfLCRWXOBJ5TVc8DzgM+3bVeSdLa9dHz3w7sq6q7q+oQcAWwY1GZ\n",
       "HcAXAKrqJuDJSSY4c5UkaVQf4X88cM/I8r3DdYcrs3+JMpKkCfEHX0lqUB8TuO8HThpZPmG4bnGZ\n",
       "E5cp87gkO0cW56tqvlsTJWnzSDIHzHXaRtcJ3JM8AbgTeDVwH/A94Jyq2jNS5vXA31bVXyQ5Ffin\n",
       "qjp1zPacwF1SB07gvhKde/5V9UiS84FdDIaRLq+qPUnOG7xcl1XVN5O8PslPgN8A7+ha7+ayZQH8\n",
       "AVzqx5aFabdgFnTu+fetxZ5/Hzx60ObQXq+9D2vJTX/wlaQGGf6S1CDDX5IaZPhLUoMMf0lqkOEv\n",
       "SQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kNMvwlqUGGvyQ1qNNMXkmeAnwZ\n",
       "OBm4C3hTVf1qiXJ3Ab8CHgUOVdX2LvVKkrrp2vN/P/CtqnoB8G3gA2PKPQrMVdVLDX5Jmr6u4b8D\n",
       "+Pzw+eeBs8aUSw91SZJ60jWQn1lVCwBVdQB45phyBVyX5OYk53asU5LU0bJj/kmuA7aOrmIQ5hct\n",
       "UXzcDOKnVdV9SZ7B4EtgT1XdeJg6d44szlfV/HLtlKRWJJkD5jpto2pcXq+oAXsYjOUvJNkGXF9V\n",
       "L1rm71wM/LqqLhnz+qpnoe9bcswBeHjr8iU3kqOB3067EVJHs/j/eMtC1cFt02zBWnKz09k+wFXA\n",
       "24GPAG8Dvr5Eo54IHFFVDyZ5EvBa4B861rvOHt46/iBGkkZlxjqKA117/k8FvgKcCNzN4FTPB5Ic\n",
       "B3ymqv4yybOBrzFI0yOBL1bVhw+zzQ3Q808Z/pJWJmyEzFptGzqF/3ow/CXNltkMf0+/lKQGGf6S\n",
       "1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KDDH9JapDhL0kN\n",
       "MvwlqUGGvyQ1qFP4Jzk7ye1JHknyssOUOyPJ3iQ/TnJBlzolSd117fnfBrwR+M64AkmOAC4FXge8\n",
       "BDgnyQs71itJ6qDTBO5VdSdAksNNH7Yd2FdVdw/LXgHsAPZ2qVuStHadwn+FjgfuGVm+l8EXwga2\n",
       "ZQGyddqtkDQLtixMuwVrsWz4J7kOGA3CMJjd/MKquno9GpVk58jifFXNr0c941Qd3DbJ+ja7JDX4\n",
       "L6ONYfoTjqubJHPAXJdtLBv+VfWaLhUA+4GTRpZPGK47XJ07O9YpSZvWsEM8/9hykotXu40+T/Uc\n",
       "15O4GXhukpOTHAW8Bbiqx3olSavU9VTPs5LcA5wKXJPk2uH645JcA1BVjwDnA7uAHwFXVNWebs2W\n",
       "JHWRqo01FpukHI/cXBzz32gc899s1pKbXuErSQ0y/CWpQYa/JDXI8JekBhn+ktQgw1+SGmT4S1KD\n",
       "DH9JapDhL0kNMvwlqUGGvyQ1yPCXpAYZ/pLUIMNfkhpk+EtSgwx/SWpQ15m8zk5ye5JHkrzsMOXu\n",
       "SvKDJN9P8r0udUqSult2Avdl3Aa8EfjnZco9CsxV1f0d69NM2rIA2TrtVugxWxam3QJNX6fwr6o7\n",
       "AZIsN31YcIipWVUHt02yvtmbNtJpFTV5kwrkAq5LcnOScydUpyRpjGV7/kmuA0YP2cMgzC+sqqtX\n",
       "WM9pVXVfkmcw+BLYU1U3HqbOnSOL81U1v8J6JGnTSzIHzHXaRlX3w+Mk1wN/V1W3rqDsxcCvq+qS\n",
       "Ma+vehZ6aZTDPmrNWnKzz2GfJStO8sQkxw6fPwl4LXB7j/VKklap66meZyW5BzgVuCbJtcP1xyW5\n",
       "ZlhsK3Bjku8D3wWurqpdXeqVJHXTy7BPnxz2UVcO+6g10x72kSTNCMNfkhpk+EtSgwx/SWqQ4S9J\n",
       "DTL8JalBhr8kNcjwl6QGGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDWo62QuH02yJ8nu\n",
       "JP+W5I/GlDsjyd4kP05yQZc6peVtWRhMLDcrjy0L6/QPIY3Vtee/C3hJVZ0C7AM+sLhAkiOAS4HX\n",
       "AS8Bzknywo71zqThpMub1kbZv6qD26oqfT+AV63HdqsObpv2vxlsnPdvvWz2/VutTuFfVd+qqkeH\n",
       "i98FTlii2HZgX1XdXVWHgCuAHV3qnWFz027AOpubdgPW2dy0G7DO5qbdgHU2N+0GbCR9jvm/E7h2\n",
       "ifXHA/eMLN87XCdJmpIjlyuQ5DoGk7A/vorBBKkXVtXVwzIXAoeq6kvr0kpJUq86T+Ce5O3AucCf\n",
       "V9Vvl3j9VGBnVZ0xXH4/UFX1kTHbm6WZtyVpQ1jtBO7L9vwPJ8kZwN8Dr1wq+IduBp6b5GTgPuAt\n",
       "wDnjtrnaHZAkrV7XMf9PAMcC1yW5NcmnAJIcl+QagKp6BDifwZlBPwKuqKo9HeuVJHXQedhHkjR7\n",
       "NsQVvknOTnJ7kkeSvGxk/clJHhoeVTx+ZDFrxu3f8LUPJNk3vFjutdNqY1+SXJzk3pH37Ixpt6mr\n",
       "zX6RYpK7kvwgyfeTfG/a7ekqyeVJFpL8cGTdU5LsSnJnkv9I8uRptrGLMfu36s/dhgh/4DbgjcB3\n",
       "lnjtJ1X1suHj3RNuV1+W3L8kLwLeBLwIOBP4VJLN8JvHJSPv2b9PuzFdNHKR4qPAXFW9tKq2T7sx\n",
       "Pfgcg/dr1PuBb1XVC4Bvs8QFqTNkqf2DVX7uNkT4V9WdVbWPwWmki818GB5m/3Yw+A3kd1V1F4Or\n",
       "pDfDh2/m37MRLVykGDZIFvShqm4E7l+0egfw+eHzzwNnTbRRPRqzf7DKz90svOHPGh7GXJ/kz6bd\n",
       "mJ4tvgBuP5vjArjzh/d7+pdZPrweauEixWJw0sbNSc6ddmPWyTOragGgqg4Az5xye9bDqj53nU71\n",
       "XI2VXCy2hJ8DJ1XV/cOx8iuTvLiqHlzn5q7aGvdvJh1uX4FPAR+qqkryj8AlwN9MvpVahdOq6r4k\n",
       "z2DwJbBn2LvczDbbmS6r/txNLPyr6jVr+DuHGB7eVNWtSf4LeD5wa8/N62wt+8egp3/iyPIJw3Ub\n",
       "2ir29TPArH/x7QdOGlmeifdoNarqvuGfv0jyNQZDXZst/BeSbK2qhSTbgP+ZdoP6VFW/GFlc0edu\n",
       "Iw77PD5uleTpwx/cSPLHwHOB/55Ww3oyOi53FfCWJEcleTaD/Zvpsy2GH6zH/BVw+7Ta0pPHL1JM\n",
       "chSDixSvmnKbepPkiUmOHT5/EvBaZv89g/+/X/ZjrgLePnz+NuDrk25Qz35v/9byuZtYz/9wkpzF\n",
       "4IKxpwPXJNldVWcCrwQ+lOR/GZyRcF5VPTDFpq7JuP2rqjuSfAW4AzgEvLtm/8KLjyY5hcH7dRdw\n",
       "3nSb001VPZLksYsUjwAu32QXKW4Fvja8rcqRwBerateU29RJki8xuIPn05L8DLgY+DDwr0neCdzN\n",
       "4Cy7mTRm/1612s+dF3lJUoM24rCPJGmdGf6S1CDDX5IaZPhLUoMMf0lqkOEvSQ0y/CWpQYa/JDXo\n",
       "/wDMoX5HllLtSwAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5db8374650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(111)\n",
    "def plotHistograms(data,binCount):\n",
    "    minVal=np.min(data)\n",
    "    maxVal=np.max(data)\n",
    "    hist=np.histogram(data, range=(minVal,maxVal), bins=binCount)\n",
    "    bin_edges = np.linspace(minVal, maxVal, binCount+1)\n",
    "    centers = .5 * (bin_edges + np.roll(bin_edges, 1))[:-1]\n",
    "    heights = np.diff(bin_edges)\n",
    "    ax=plt.subplot(111)\n",
    "    lefts = 0 - .5 * hist[0]\n",
    "    ax.barh(centers, hist[0], height=heights, left=lefts)\n",
    "\n",
    "data=np.random.normal(0, 1, 100)\n",
    "binCount=10\n",
    "plotHistograms(data,binCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above function to plot multiple histograms on the same plot corresponding to the datasets given below. An example graph below shows how multiple histograms can be accommodated in the same plot. Use bin count of 100 for each of the histograms. You are free to modify the function, or write your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_of_data_points = 100\n",
    "data_sets = [np.random.normal(0, 1, number_of_data_points),\n",
    "             np.random.normal(6, 1, number_of_data_points),\n",
    "             np.random.normal(-3, 1, number_of_data_points),\n",
    "             np.random.normal(3, 1, number_of_data_points),\n",
    "             np.random.normal(-6, 1, number_of_data_points),\n",
    "             np.random.normal(12, 1, number_of_data_points)\n",
    "            ]\n",
    "ax = plt.subplot(111)\n",
    "#Write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"histograms.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
